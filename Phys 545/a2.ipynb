{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, chi2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "From https://www.stat.ubc.ca/~rollin/stats/ssize/b2.html, we get\n",
    "\n",
    "* **10% vs 15%**: $n=686$\n",
    "* **25% vs 30%**: $n=1251$\n",
    "* **40% vs 45%**: $n=1534$\n",
    "* **45% vs 50%**: $n=1565$\n",
    "* **55% vs 60%**: $n=1534$\n",
    "\n",
    "where $n$ is the sample size per group. Let $p=(p_1+p_2)/2$ in each case. The observed pattern here is that as $p(1-p)$ increases/decreases, so too does $n$.\n",
    "\n",
    "In the limit of large $N$, a binomial distribution converges to a Gaussian distribution with mean $Np$ and standard deviation $\\sqrt{Np(1-p)}$. The distribution of the estimator $\\hat{p}$ (which we get from sampling from the binomial distribution) thus has mean $p$ and standard error $\\sqrt{p(1-p)/N}$. Now when comparing two distinct populations, the power is propotional to the standard error of the two population parameters $p_1$ and $p_2$. To maintain a constant power, a constant standard error must be achieved: thus, as $p(1-p)$ increases, so too must $N$. This explains why the sample size must vary when the difference we are trying to detect remains constant: the standard errors themselves depend on the magnitude of $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "From https://www.stat.ubc.ca/~rollin/stats/ssize/n2.html\n",
    "\n",
    "* **Group 1**: $n=142$\n",
    "* **Group 2**: $n=142$\n",
    "\n",
    "## Part A\n",
    "\n",
    "The two groups have the same required value of $n$: this follows from the fact that at $\\alpha=0.05$ (two sided) we have\n",
    "\n",
    "$$\\text{Power} = \\text{erf}\\left(\\frac{\\Delta}{\\sigma} \\sqrt{\\frac{N}{2}} - 1.96\\right)$$\n",
    "\n",
    "where $\\Delta$ is the difference between means of the two populations and $\\sigma$ is the standard deviation of each population. In each case:\n",
    "\n",
    "* **Group 1:** $\\Delta/\\sigma = (54-44)/30 = 1/3$\n",
    "* **Group 2:** $\\Delta/\\sigma = (21-18)/9 = 1/3$\n",
    "\n",
    "Since $\\Delta/\\sigma$ is constant for each group, the same value of $N$ will give the same power.\n",
    "\n",
    "## Part B\n",
    "\n",
    "Assuming populations are normally distributed, the power at $\\alpha=0.05$ (two-sided) is given by \n",
    "\n",
    "$$\\text{Power} = \\text{erf}\\left(\\frac{\\Delta}{\\sigma} \\sqrt{\\frac{N}{2}} - 1.96\\right)$$\n",
    "\n",
    "If one wishes to decrease $N$ but maintain constant Power, there is only one option: increase $\\Delta/\\sigma$. This can be done by\n",
    "\n",
    "1. Increase $\\Delta$. In other words, assume (apriori) that the effect you expect to see is more significant than you otherwise would have believed. This will make the chances of rejecting the null hypothesis slimmer (less likely to see statistically significant results).\n",
    "\n",
    "2. Decrease $\\sigma$. In other words, assume (apriori) that the populations you are dealing with are fairly uniform (i.e. exhibit little variance). Once again, this will make the chances of rejecting the null hypothesis slimmer (less likely to see statistically significant results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value corresponds to the probability of getting a **difference of means** in an pre-specified **extreme** region given that there is *no difference between the group before and after intervention* (the null). In this particular example, if it supposed that the intervention will *increase the magnitude of the variable measured*, the **extreme** region will be specified by a **one-tailed test**.\n",
    "\n",
    "* Note that while group 1 had a smaller mean change than group two, the standard error (of the mean change) was smaller for group 1 than it was for group 2. Mathematically, the probability of getting a result $\\Delta \\mu$ or greater (in a two-tailed test) when the standard error is $\\sigma$ is\n",
    "\n",
    "$$\\frac{p}{2} = \\int_{\\Delta \\mu}^{\\infty} N(0,\\sigma)dx = \\int_{\\Delta \\mu/\\sigma}^{\\infty} N(0,1)dx = 1-\\text{erf}(\\Delta \\mu/\\sigma)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13361440253771617"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proof: Group 2\n",
    "2*(1-norm.cdf(12/8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the quantity of relevance is $\\Delta \\mu/\\sigma$.\n",
    "\n",
    "* **Group 1**: $\\Delta \\mu/\\sigma=2$\n",
    "* **Group 2**: $\\Delta \\mu/\\sigma=1.5$\n",
    "\n",
    "Thus the p-value for group 1 is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paired t-test yields statistics that enable testing the null that the changes are the same in each group. The results obtained from the tests $(\\Delta \\mu_1, \\sigma_{\\Delta \\mu_1})$ and $(\\Delta \\mu_2, \\sigma_{\\Delta \\mu_2})$, can be compared with eachother (assuming normalilty) to determine if there is sufficient evidence to suggest that *they are not the same* (in otherwords, testing the null that they are the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could use the website, or I could just code it myself... First the table that I used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57, 23],\n",
       "       [24, 83]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_obs = np.array([[57,23],[24,83]])\n",
    "arr_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns represent levels of loneliness and rows represent high/low time spent on social media. Now we get our expected array (assuming no relationship) and use this to compute a $\\chi^2$ value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 = 44.4346\n"
     ]
    }
   ],
   "source": [
    "n_row = np.expand_dims(np.sum(arr,axis=1),axis=0)\n",
    "n_col = np.expand_dims(np.sum(arr,axis=0),axis=0)\n",
    "n = np.sum(arr)\n",
    "arr_exp = n_row.T@n_col / n\n",
    "c2 = np.sum((arr_obs-arr_exp)**2 / arr_exp)\n",
    "print(f'chi2 = {c2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to a p-value of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=2.63e-11\n"
     ]
    }
   ],
   "source": [
    "p = 1 - chi2(1).cdf(c2)\n",
    "print(f'p={p:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is significant at $p<0.05$. The conclusion of the study is that there is evidence to suggest that the amount of time one spends on social media is related to reported levels of loneliness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the prevalence is 40% and $n=1000$ we have\n",
    "\n",
    "* $TP + FN = 400$\n",
    "* $TN + FP = 600$\n",
    "\n",
    "Now since $\\text{Sensitivity} \\equiv TP/(TP+FP)$ and $\\text{Specificity} \\equiv TN/(TN+FN)$ we get\n",
    "\n",
    "* $TP = \\text{Sens} \\cdot (TP+FP) = 0.95 \\cdot 400 = 380$\n",
    "* $FP = 20$\n",
    "* $TN = \\text{Spec} \\cdot (TN+FN) = 0.90 \\cdot 600 = 540$\n",
    "* $FN = 60$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our 2x2 table is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Has Disease</th>\n",
       "      <th>No Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Positive</th>\n",
       "      <td>380</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Negative</th>\n",
       "      <td>60</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Has Disease  No Disease\n",
       "Test Positive          380          20\n",
       "Test Negative           60         540"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([[380,20],[60,540]]),\n",
    "            columns=['Has Disease', 'No Disease'],\n",
    "            index = ['Test Positive', 'Test Negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ppv and npv are given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Preditive Value: 86.36%\n",
      "Negative Preditive Value: 96.43%\n"
     ]
    }
   ],
   "source": [
    "sens = 0.95\n",
    "spec = 0.9\n",
    "prev = 0.4\n",
    "ppv = sens*prev/(sens*prev + (1-spec)*(1-prev))\n",
    "npv = spec*(1-prev)/((1-sens)*prev + spec*(1-prev))\n",
    "print(f'Positive Preditive Value: {100*ppv:.2f}%')\n",
    "print(f'Negative Preditive Value: {100*npv:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No consider the **new population**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the prevalence is 5% and $n=2000$ we have\n",
    "\n",
    "* $TP + FP = 100$\n",
    "* $TN + FN = 1900$\n",
    "\n",
    "Now since $\\text{Sensitivity} \\equiv TP/(TP+FP)$ and $\\text{Specificity} \\equiv TN/(TN+FN)$ we get\n",
    "\n",
    "* $TP = \\text{Sens} \\cdot (TP+FP) = 0.95 \\cdot 100 = 95$\n",
    "* $FP = 5$\n",
    "* $TN = \\text{Spec} \\cdot (TN+FN) = 0.90 \\cdot 1900 = 1710$\n",
    "* $FN = 190$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Has Disease</th>\n",
       "      <th>No Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test Positive</th>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Negative</th>\n",
       "      <td>190</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Has Disease  No Disease\n",
       "Test Positive           95           5\n",
       "Test Negative          190        1710"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([[95,5],[190,1710]]),\n",
    "            columns=['Has Disease', 'No Disease'],\n",
    "            index = ['Test Positive', 'Test Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Preditive Value: 33.33%\n",
      "Negative Preditive Value: 99.71%\n"
     ]
    }
   ],
   "source": [
    "sens = 0.95\n",
    "spec = 0.9\n",
    "prev = 0.05\n",
    "ppv = sens*prev/(sens*prev + (1-spec)*(1-prev))\n",
    "npv = spec*(1-prev)/((1-sens)*prev + spec*(1-prev))\n",
    "print(f'Positive Preditive Value: {100*ppv:.2f}%')\n",
    "print(f'Negative Preditive Value: {100*npv:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the first population, the probability of ruling in/out disease exceeds 85% in both cases (provided person being tested is randomly sampled). The test is slightly better at ruling out disease. In the second population, however, due to the low prevalence of the disease, the positive predictive value is very low; this is because the likelihood of having the disease is low to begin with. As such, *when randomly sampling* in the second population, the test is not a good metric as to whether or not a patient has the disease. However, the test is a very good indicator of when somebody doesn't have the disease**.\n",
    "\n",
    "* **Note**: in the second population, one could simply assume that no one has the disease, this would give an npv of 95%. While this seems good, it only works because of the low prevalence of disease in the population.\n",
    "\n",
    "* **Note**: in reality, the situation is more complicated. Patients who get tested for disease are not *randomly sampled* from the population; they are likely receiving the test because they have prior reason to believe they have the illness. In such a scenario, Bayesian statistics would have to be used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
